{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np  \n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy import stats\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NaiveBayesClassifier:\n",
    "    def __init__(self):\n",
    "        self.classes = None\n",
    "        self.means = None\n",
    "        self.variances = None\n",
    "        self.priors = None\n",
    "        self.M_s=0\n",
    "        self.Perror=0\n",
    "        self.M = None\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.classes = np.unique(y)\n",
    "        n_classes = len(self.classes)\n",
    "        n_features = X.shape[1]\n",
    "        self.means = np.zeros((n_classes, n_features))\n",
    "        self.variances = np.zeros((n_classes, n_features))   \n",
    "        self.priors = np.zeros(n_classes)\n",
    "    \n",
    "        # 計算先驗機率\n",
    "        for i, c in enumerate(self.classes):\n",
    "            X_c = X[y == c]\n",
    "            self.priors[i] = X_c.shape[0] / X.shape[0]\n",
    "            if X_c.shape[0] == 0:\n",
    "                self.means[i] = np.zeros(n_features)\n",
    "                self.variances[i] = np.zeros(n_features)\n",
    "            else:\n",
    "                self.means[i] = np.mean(X_c, axis=0)\n",
    "                self.variances[i] = np.var(X_c, axis=0) + 1e-9\n",
    "\n",
    "    def predict(self, X):\n",
    "        return np.argmax(self.predict_proba(X), axis=1) + 1\n",
    "\n",
    "    def score(self,X,labels_X):\n",
    "        predict = self.predict(X)\n",
    "        result = [labels_X[i] == predict[i] for i in range(len(X))]\n",
    "        return np.sum(result)/len(X)\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        likelihood = np.zeros((X.shape[0], len(self.classes)))\n",
    "        for i, c in enumerate(self.classes):\n",
    "            class_likelihood = stats.norm.pdf(X, loc=self.means[i], scale=np.sqrt(self.variances[i]))\n",
    "            class_likelihood = np.prod(class_likelihood, axis=1)\n",
    "            likelihood[:, i] = class_likelihood * self.priors[i]\n",
    "        evidence = np.sum(likelihood * self.priors, axis=1) + 1e-10\n",
    "        return likelihood / evidence.reshape(-1, 1)\n",
    "\n",
    "    def fit2(self, X, y):\n",
    "        self.classes = np.unique(y)\n",
    "        n_classes = len(self.classes)\n",
    "        n_features = X.shape[1]\n",
    "        self.means = np.zeros((n_classes, n_features))\n",
    "        self.variances = np.zeros((n_classes, n_features, n_features))   \n",
    "        self.priors = np.zeros(n_classes)\n",
    "\n",
    "        # 計算先驗機率\n",
    "        for i, c in enumerate(self.classes):\n",
    "            X_c = X[y == c]\n",
    "            self.priors[i] = X_c.shape[0] / X.shape[0]\n",
    "            if X_c.shape[0] == 0:\n",
    "                self.means[i] = np.zeros(n_features)\n",
    "                self.variances[i] = np.zeros((n_features, n_features))\n",
    "            else:\n",
    "                self.means[i] = np.mean(X_c, axis=0)\n",
    "                self.variances[i] = np.cov(X_c, rowvar=False) + 1e-6*np.eye(n_features)\n",
    "    \n",
    "\n",
    "    def Bayes_error(self):\n",
    "        # initialize M matrix\n",
    "        n_classes = len(self.classes)\n",
    "            \n",
    "        if len(self.variances.shape) == 1:\n",
    "            self.variances = self.variances.reshape(-1, 1)\n",
    "\n",
    "        M = np.zeros((n_classes, n_classes))\n",
    "\n",
    "        # calculate M matrix entries using loops\n",
    "        for i in range(n_classes):\n",
    "            for j in range(i+1, n_classes):\n",
    "                delta = self.means[i]-self.means[j]\n",
    "                sigma = 0.5*(self.variances[i]+self.variances[j])\n",
    "                sigma_inv = np.linalg.pinv(sigma)\n",
    "                m_ij = 0.125 * np.dot(delta.T, np.dot(sigma_inv, delta)) + 0.5 * np.log(np.linalg.det(sigma) / np.sqrt(np.linalg.det(self.variances[i]) * np.linalg.det(self.variances[j])))\n",
    "                M[i,j] = m_ij\n",
    "                M[j,i] = m_ij\n",
    "\n",
    "        s_values = np.linspace(0.1, 0.9, 20)\n",
    "        \n",
    "        # 找出最佳的 s 值\n",
    "        opt_s = 0\n",
    "        min_error = float('inf')\n",
    "        \n",
    "        for s in s_values:    \n",
    "            Perrors = []\n",
    "            for i in range(3):\n",
    "                for j in range(i+1, 3):\n",
    "                    alpha_ij = math.sqrt(np.linalg.det(s*self.variances[i]+(1-s)*self.variances[j])/np.sqrt(np.linalg.det(self.variances[i])*np.linalg.det(self.variances[j])))\n",
    "                    Perror = 0.25 * (1 - alpha_ij) * ((self.priors[i]*math.sqrt(s) - self.priors[j]*math.sqrt(1-s))**2 + (self.priors[i]*math.sqrt(1-s) - self.priors[j]*math.sqrt(s))**2)\n",
    "                    Perrors.append(Perror)\n",
    "            \n",
    "            # 输出结果\n",
    "            print(f\"For s={s}:\")\n",
    "            for i in range(3):\n",
    "                for j in range(i+1, 3):\n",
    "                    print(f\"Perror({i+1},{j+1}) = {Perrors[i*2+j-3]}\")\n",
    "            \n",
    "            # 找到更好的 s 值時更新最佳 s 值與對應的誤差率\n",
    "            min_idx = np.argmin(Perrors)\n",
    "            if Perrors[min_idx] < min_error:\n",
    "                min_error = Perrors[min_idx]\n",
    "                opt_s = s_values[min_idx // 3]\n",
    "                \n",
    "        print(\"Optimal s: {}\".format(opt_s))\n",
    "        print(\"Bayes error rate: {}\".format(min_error))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     label  Alcohol  Malic acid   Ash  Alcalinity of ash  Magnesium   \n",
      "160      3    12.36        3.83  2.38               21.0         88  \\\n",
      "87       2    11.65        1.67  2.62               26.0         88   \n",
      "172      3    14.16        2.51  2.48               20.0         91   \n",
      "38       1    13.07        1.50  2.10               15.5         98   \n",
      "9        1    13.86        1.35  2.27               16.0         98   \n",
      "\n",
      "     Total phenols  Flavanoids  Nonflavanoid phenols  Proanthocyanins   \n",
      "160           2.30        0.92                  0.50             1.04  \\\n",
      "87            1.92        1.61                  0.40             1.34   \n",
      "172           1.68        0.70                  0.44             1.24   \n",
      "38            2.40        2.64                  0.28             1.37   \n",
      "9             2.98        3.15                  0.22             1.85   \n",
      "\n",
      "     Color intensity   Hue  OD280/OD315 of diluted wines  Proline  \n",
      "160             7.65  0.56                          1.58      520  \n",
      "87              2.60  1.36                          3.21      562  \n",
      "172             9.70  0.62                          1.71      660  \n",
      "38              3.70  1.18                          2.69     1020  \n",
      "9               7.22  1.01                          3.55     1045  \n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 178 entries, 160 to 150\n",
      "Data columns (total 14 columns):\n",
      " #   Column                        Non-Null Count  Dtype  \n",
      "---  ------                        --------------  -----  \n",
      " 0   label                         178 non-null    int64  \n",
      " 1   Alcohol                       178 non-null    float64\n",
      " 2   Malic acid                    178 non-null    float64\n",
      " 3   Ash                           178 non-null    float64\n",
      " 4   Alcalinity of ash             178 non-null    float64\n",
      " 5   Magnesium                     178 non-null    int64  \n",
      " 6   Total phenols                 178 non-null    float64\n",
      " 7   Flavanoids                    178 non-null    float64\n",
      " 8   Nonflavanoid phenols          178 non-null    float64\n",
      " 9   Proanthocyanins               178 non-null    float64\n",
      " 10  Color intensity               178 non-null    float64\n",
      " 11  Hue                           178 non-null    float64\n",
      " 12  OD280/OD315 of diluted wines  178 non-null    float64\n",
      " 13  Proline                       178 non-null    int64  \n",
      "dtypes: float64(11), int64(3)\n",
      "memory usage: 20.9 KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# 指定特徵名稱\n",
    "feature_names = ['label',\n",
    "                 'Alcohol', \n",
    "                 'Malic acid',\n",
    "                 'Ash',\n",
    "                 'Alcalinity of ash' ,\n",
    "                 'Magnesium',\n",
    "                 'Total phenols',\n",
    "                 'Flavanoids',\n",
    "                 'Nonflavanoid phenols',\n",
    "                 'Proanthocyanins',\n",
    "                 'Color intensity',\n",
    "                 'Hue',\n",
    "                 'OD280/OD315 of diluted wines',\n",
    "                 'Proline' ]\n",
    "data=pd.read_csv(\"wine.data\", names=feature_names)\n",
    "data=data.sample(frac=1)\n",
    "half = len(data) // 2\n",
    "print(data.head()) # show first 5 items.\n",
    "print(data.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'> (89, 14)\n",
      "<class 'pandas.core.frame.DataFrame'> (89, 14)\n",
      "     label  Alcohol  Malic acid   Ash  Alcalinity of ash  Magnesium   \n",
      "160      3    12.36        3.83  2.38               21.0         88  \\\n",
      "87       2    11.65        1.67  2.62               26.0         88   \n",
      "172      3    14.16        2.51  2.48               20.0         91   \n",
      "38       1    13.07        1.50  2.10               15.5         98   \n",
      "9        1    13.86        1.35  2.27               16.0         98   \n",
      "..     ...      ...         ...   ...                ...        ...   \n",
      "51       1    13.83        1.65  2.60               17.2         94   \n",
      "134      3    12.51        1.24  2.25               17.5         85   \n",
      "99       2    12.29        3.17  2.21               18.0         88   \n",
      "116      2    11.82        1.47  1.99               20.8         86   \n",
      "1        1    13.20        1.78  2.14               11.2        100   \n",
      "\n",
      "     Total phenols  Flavanoids  Nonflavanoid phenols  Proanthocyanins   \n",
      "160           2.30        0.92                  0.50             1.04  \\\n",
      "87            1.92        1.61                  0.40             1.34   \n",
      "172           1.68        0.70                  0.44             1.24   \n",
      "38            2.40        2.64                  0.28             1.37   \n",
      "9             2.98        3.15                  0.22             1.85   \n",
      "..             ...         ...                   ...              ...   \n",
      "51            2.45        2.99                  0.22             2.29   \n",
      "134           2.00        0.58                  0.60             1.25   \n",
      "99            2.85        2.99                  0.45             2.81   \n",
      "116           1.98        1.60                  0.30             1.53   \n",
      "1             2.65        2.76                  0.26             1.28   \n",
      "\n",
      "     Color intensity   Hue  OD280/OD315 of diluted wines  Proline  \n",
      "160             7.65  0.56                          1.58      520  \n",
      "87              2.60  1.36                          3.21      562  \n",
      "172             9.70  0.62                          1.71      660  \n",
      "38              3.70  1.18                          2.69     1020  \n",
      "9               7.22  1.01                          3.55     1045  \n",
      "..               ...   ...                           ...      ...  \n",
      "51              5.60  1.24                          3.37     1265  \n",
      "134             5.45  0.75                          1.51      650  \n",
      "99              2.30  1.42                          2.83      406  \n",
      "116             1.95  0.95                          3.33      495  \n",
      "1               4.38  1.05                          3.40     1050  \n",
      "\n",
      "[89 rows x 14 columns]\n"
     ]
    }
   ],
   "source": [
    "train=data.iloc[:half]\n",
    "test=data.iloc[half:]\n",
    "print(type(train),train.shape)\n",
    "print(type(test),test.shape)\n",
    "print(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160    3\n",
      "87     2\n",
      "172    3\n",
      "38     1\n",
      "9      1\n",
      "Name: label, dtype: int64\n",
      "     label  Alcohol  Malic acid   Ash  Alcalinity of ash  Magnesium   \n",
      "160      3    12.36        3.83  2.38               21.0         88  \\\n",
      "87       2    11.65        1.67  2.62               26.0         88   \n",
      "172      3    14.16        2.51  2.48               20.0         91   \n",
      "38       1    13.07        1.50  2.10               15.5         98   \n",
      "9        1    13.86        1.35  2.27               16.0         98   \n",
      "..     ...      ...         ...   ...                ...        ...   \n",
      "51       1    13.83        1.65  2.60               17.2         94   \n",
      "134      3    12.51        1.24  2.25               17.5         85   \n",
      "99       2    12.29        3.17  2.21               18.0         88   \n",
      "116      2    11.82        1.47  1.99               20.8         86   \n",
      "1        1    13.20        1.78  2.14               11.2        100   \n",
      "\n",
      "     Total phenols  Flavanoids  Nonflavanoid phenols  Proanthocyanins   \n",
      "160           2.30        0.92                  0.50             1.04  \\\n",
      "87            1.92        1.61                  0.40             1.34   \n",
      "172           1.68        0.70                  0.44             1.24   \n",
      "38            2.40        2.64                  0.28             1.37   \n",
      "9             2.98        3.15                  0.22             1.85   \n",
      "..             ...         ...                   ...              ...   \n",
      "51            2.45        2.99                  0.22             2.29   \n",
      "134           2.00        0.58                  0.60             1.25   \n",
      "99            2.85        2.99                  0.45             2.81   \n",
      "116           1.98        1.60                  0.30             1.53   \n",
      "1             2.65        2.76                  0.26             1.28   \n",
      "\n",
      "     Color intensity   Hue  OD280/OD315 of diluted wines  Proline  \n",
      "160             7.65  0.56                          1.58      520  \n",
      "87              2.60  1.36                          3.21      562  \n",
      "172             9.70  0.62                          1.71      660  \n",
      "38              3.70  1.18                          2.69     1020  \n",
      "9               7.22  1.01                          3.55     1045  \n",
      "..               ...   ...                           ...      ...  \n",
      "51              5.60  1.24                          3.37     1265  \n",
      "134             5.45  0.75                          1.51      650  \n",
      "99              2.30  1.42                          2.83      406  \n",
      "116             1.95  0.95                          3.33      495  \n",
      "1               4.38  1.05                          3.40     1050  \n",
      "\n",
      "[89 rows x 14 columns]\n",
      "(89, 14)\n",
      "[3 2 3 1 1 2 3 3 2 2 2 2 2 1 1 3 3 3 3 1 1 1 1 2 2 1 2 2 3 1 2 1 2 2 3 2 1\n",
      " 3 3 2 1 3 3 3 2 1 2 3 1 1 2 2 2 2 3 1 3 2 1 1 1 3 1 2 2 2 2 1 3 3 1 2 2 1\n",
      " 3 2 1 1 2 2 3 1 3 2 1 3 2 2 1]\n",
      "(89,)\n",
      "[[-0.92245583 -0.92206932 -1.56822102 ... -0.41649742  0.48265097\n",
      "  -1.42381084]\n",
      " [-0.14863629 -0.64542847  0.46369587 ...  0.56572633  1.30742658\n",
      "   0.88471161]\n",
      " [ 2.283368   -0.60973287 -0.76246087 ...  0.52302095  0.25279547\n",
      "   0.98322608]\n",
      " ...\n",
      " [-0.18548484  0.93410154 -0.30703122 ... -1.01437274 -1.23450481\n",
      "  -0.19894758]\n",
      " [ 0.45322336 -1.23440576 -0.09683292 ...  0.26678867 -0.9911284\n",
      "   0.01450044]\n",
      " [ 0.64974896  0.71100408  0.81402637 ... -1.56954268 -1.84294584\n",
      "  -0.80645348]]\n",
      "(89, 13)\n"
     ]
    }
   ],
   "source": [
    "# 抽出標籤那一行\n",
    "labels = train.iloc[:,0]\n",
    "labels_test= test.iloc[:,0]\n",
    "print(labels.head())\n",
    "# 初始化標準化器\n",
    "scaler = StandardScaler()\n",
    "# 對特徵值進行標準化\n",
    "print(train)\n",
    "print(train.shape)\n",
    "labels = train.iloc[:,0].values\n",
    "labels_test = test.iloc[:,0].values\n",
    "train = train.drop(\"label\",axis=1)\n",
    "test  = test.drop(\"label\",axis=1)\n",
    "train_features = scaler.fit_transform(train.iloc[:,:])\n",
    "test_features  = scaler.transform(test.iloc[:, :])\n",
    "print(labels)\n",
    "print(labels.shape)\n",
    "print(test_features)\n",
    "print(test_features.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hw1結果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 1 1 1 3 2 2 1 3 3 3 2 2 2 2 1 2 1 2 2 3 1 1 3 2 2 1 2 2 2 3 3 2 2 2 2 3\n",
      " 2 3 1 3 3 2 1 2 1 2 3 3 2 3 2 1 3 1 2 1 3 2 1 1 1 3 1 1 1 2 1 1 1 1 2 1 3\n",
      " 1 3 1 3 2 2 2 2 1 3 2 3 3 2 3]\n",
      "[2 1 1 1 3 2 2 1 3 3 3 2 2 2 2 1 2 1 2 2 3 1 1 2 2 2 1 2 2 2 3 3 2 2 2 2 3\n",
      " 2 3 1 3 3 2 1 2 1 2 3 3 2 3 2 1 3 1 1 1 3 2 1 1 1 3 1 1 1 2 1 1 1 1 2 1 2\n",
      " 1 3 1 3 2 2 2 2 1 3 2 3 3 2 3]\n",
      "0.9662921348314607\n"
     ]
    }
   ],
   "source": [
    "nb = NaiveBayesClassifier()\n",
    "nb.fit(train_features, labels)\n",
    "x1=nb.predict(test_features)\n",
    "print(x1)\n",
    "print(labels_test)\n",
    "print(nb.score(test_features,labels_test))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hw2結果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For s=0.1:\n",
      "Perror(1,2) = -0.008456251599105225\n",
      "Perror(1,3) = -0.0031007617455811984\n",
      "Perror(2,3) = -0.008456251599105225\n",
      "For s=0.14210526315789473:\n",
      "Perror(1,2) = -0.011471692944190945\n",
      "Perror(1,3) = -0.007823020535984083\n",
      "Perror(2,3) = -0.011471692944190945\n",
      "For s=0.1842105263157895:\n",
      "Perror(1,2) = -0.012390463925401269\n",
      "Perror(1,3) = -0.010438230894327223\n",
      "Perror(2,3) = -0.012390463925401269\n",
      "For s=0.22631578947368422:\n",
      "Perror(1,2) = -0.011813411150345942\n",
      "Perror(1,3) = -0.01150263986446985\n",
      "Perror(2,3) = -0.011813411150345942\n",
      "For s=0.26842105263157895:\n",
      "Perror(1,2) = -0.010250108208674372\n",
      "Perror(1,3) = -0.011463485211286508\n",
      "Perror(2,3) = -0.010250108208674372\n",
      "For s=0.31052631578947365:\n",
      "Perror(1,2) = -0.008152148168797932\n",
      "Perror(1,3) = -0.010716241946099131\n",
      "Perror(2,3) = -0.008152148168797932\n",
      "For s=0.3526315789473684:\n",
      "Perror(1,2) = -0.005919104910237621\n",
      "Perror(1,3) = -0.009622096308393446\n",
      "Perror(2,3) = -0.005919104910237621\n",
      "For s=0.39473684210526316:\n",
      "Perror(1,2) = -0.003895670150696391\n",
      "Perror(1,3) = -0.00851059178323956\n",
      "Perror(2,3) = -0.003895670150696391\n",
      "For s=0.4368421052631579:\n",
      "Perror(1,2) = -0.0023660861334810677\n",
      "Perror(1,3) = -0.007675882528847541\n",
      "Perror(2,3) = -0.0023660861334810677\n",
      "For s=0.4789473684210527:\n",
      "Perror(1,2) = -0.0015482666835391872\n",
      "Perror(1,3) = -0.007370057844344453\n",
      "Perror(2,3) = -0.0015482666835391872\n",
      "For s=0.5210526315789473:\n",
      "Perror(1,2) = -0.0015886479788631478\n",
      "Perror(1,3) = -0.007795185384802345\n",
      "Perror(2,3) = -0.0015886479788631478\n",
      "For s=0.5631578947368421:\n",
      "Perror(1,2) = -0.0025582476660733298\n",
      "Perror(1,3) = -0.009094960170949493\n",
      "Perror(2,3) = -0.0025582476660733298\n",
      "For s=0.6052631578947368:\n",
      "Perror(1,2) = -0.004450143870434518\n",
      "Perror(1,3) = -0.011346491850783591\n",
      "Perror(2,3) = -0.004450143870434518\n",
      "For s=0.6473684210526316:\n",
      "Perror(1,2) = -0.007178434704757616\n",
      "Perror(1,3) = -0.014552582647078316\n",
      "Perror(2,3) = -0.007178434704757616\n",
      "For s=0.6894736842105262:\n",
      "Perror(1,2) = -0.010578626425616935\n",
      "Perror(1,3) = -0.018634755020705326\n",
      "Perror(2,3) = -0.010578626425616935\n",
      "For s=0.731578947368421:\n",
      "Perror(1,2) = -0.014409279919602254\n",
      "Perror(1,3) = -0.023427259901504734\n",
      "Perror(2,3) = -0.014409279919602254\n",
      "For s=0.7736842105263158:\n",
      "Perror(1,2) = -0.018354583169546128\n",
      "Perror(1,3) = -0.02867238356854337\n",
      "Perror(2,3) = -0.018354583169546128\n",
      "For s=0.8157894736842105:\n",
      "Perror(1,2) = -0.02202728038522245\n",
      "Perror(1,3) = -0.03401782534469074\n",
      "Perror(2,3) = -0.02202728038522245\n",
      "For s=0.8578947368421053:\n",
      "Perror(1,2) = -0.024971154657181978\n",
      "Perror(1,3) = -0.039018835123118496\n",
      "Perror(2,3) = -0.024971154657181978\n",
      "For s=0.9:\n",
      "Perror(1,2) = -0.026663143068389895\n",
      "Perror(1,3) = -0.043156811447094205\n",
      "Perror(2,3) = -0.026663143068389895\n",
      "Optimal s: 0.1\n",
      "Bayes error rate: -0.043156811447094205\n"
     ]
    }
   ],
   "source": [
    "nb.fit2(test_features, labels)\n",
    "nb.Bayes_error()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "e72190538c2ba43f01a4bb1f8db058440a9aceb794ef196497a6a1a579de28d1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
